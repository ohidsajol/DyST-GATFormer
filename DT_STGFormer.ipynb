{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "230f85e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10bf1cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a95aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DEAPDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir,\n",
    "        label_type=\"valence\",   # \"valence\" or \"arousal\"\n",
    "        window_size=256,        # 2 seconds @ 128 Hz\n",
    "        step_size=128,          # 50% overlap\n",
    "        transform=None\n",
    "    ):\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "        self.subject_ids = []\n",
    "\n",
    "        label_idx = {\"valence\": 0, \"arousal\": 1}[label_type]\n",
    "\n",
    "        for file in sorted(os.listdir(data_dir)):\n",
    "            if not file.endswith(\".dat\"):\n",
    "                continue\n",
    "            \n",
    "            subject_id = int(file[1:3])  # s01 → 1\n",
    "            path = os.path.join(data_dir, file)\n",
    "            with open(path, \"rb\") as f:\n",
    "                subject = pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "            eeg = subject[\"data\"][:, :32, :]    # (40, 32, 8064)\n",
    "            labels = subject[\"labels\"][:, label_idx]\n",
    "\n",
    "            for trial in range(eeg.shape[0]):\n",
    "                signal = eeg[trial]\n",
    "                label = 1 if labels[trial] >= 5 else 0\n",
    "\n",
    "                # Sliding window segmentation\n",
    "                for start in range(0, signal.shape[1] - window_size, step_size):\n",
    "                    window = signal[:, start:start + window_size]\n",
    "                    self.samples.append(window)\n",
    "                    self.labels.append(label)\n",
    "                    self.subject_ids.append(subject_id)\n",
    "\n",
    "        self.samples = np.array(self.samples, dtype=np.float32)\n",
    "        self.labels = np.array(self.labels, dtype=np.int64)\n",
    "\n",
    "        print(f\"Loaded {len(self.samples)} samples\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.samples[idx]\n",
    "        y = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return torch.tensor(x), torch.tensor(y), self.subject_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78e2eb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loso_split(dataset, test_subject):\n",
    "    train_idx = []\n",
    "    test_idx = []\n",
    "\n",
    "    for i, s in enumerate(dataset.subject_ids):\n",
    "        if s == test_subject:\n",
    "            test_idx.append(i)\n",
    "        else:\n",
    "            train_idx.append(i)\n",
    "\n",
    "    return Subset(dataset, train_idx), Subset(dataset, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd6d6a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y, _ in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            preds = model(x).argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "    if total == 0:\n",
    "        return 0.0   # or np.nan\n",
    "\n",
    "    return 100.0 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d05bb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiScaleTemporalCNN(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_ch, out_ch, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_ch, out_ch, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv1d(in_ch, out_ch, kernel_size=7, padding=3)\n",
    "        self.bn = nn.BatchNorm1d(out_ch * 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, T)\n",
    "        f1 = self.conv1(x)\n",
    "        f2 = self.conv2(x)\n",
    "        f3 = self.conv3(x)\n",
    "        out = torch.cat([f1, f2, f3], dim=1)\n",
    "        return self.bn(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "541e5503",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicGraphLearner(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.theta = nn.Linear(in_features, in_features, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, F)\n",
    "        theta_x = self.theta(x)\n",
    "        A = torch.matmul(theta_x, x.transpose(1, 2))\n",
    "        A = F.softmax(A, dim=-1)\n",
    "        return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2513b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphTransformerEncoder(nn.Module):\n",
    "    def __init__(self, dim, heads):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        self.scale = dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        # x: (B, C, F)\n",
    "        # adj: (B, C, C)\n",
    "\n",
    "        B, C, F = x.shape\n",
    "        qkv = self.qkv(x).chunk(3, dim=-1)\n",
    "\n",
    "        q, k, v = [\n",
    "            t.reshape(B, C, self.heads, F // self.heads).transpose(1, 2)\n",
    "            for t in qkv\n",
    "        ]  # (B, H, C, F/H)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale  # (B, H, C, C)\n",
    "\n",
    "        attn = attn * adj.unsqueeze(1)\n",
    "\n",
    "        attn = attn.softmax(dim=-1)\n",
    "\n",
    "        out = (attn @ v).transpose(1, 2).reshape(B, C, F)\n",
    "        out = self.proj(out)\n",
    "\n",
    "        return self.norm(x + out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7861365",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DySTGATFormer(nn.Module):\n",
    "    def __init__(self, channels=32, time_steps=256, num_classes=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.temporal = MultiScaleTemporalCNN(channels, 32)  # → (B, 96, T)\n",
    "\n",
    "        self.graph_learner = DynamicGraphLearner(96)\n",
    "\n",
    "        self.transformer = GraphTransformerEncoder(dim=96, heads=4)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(96, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, T)\n",
    "\n",
    "        x = self.temporal(x)        # (B, 96, T)\n",
    "        x = x.permute(0, 2, 1)     # (B, T, 96)\n",
    "\n",
    "        x = x.mean(dim=1)          # temporal aggregation → (B, 96)\n",
    "\n",
    "        x = x.unsqueeze(1).repeat(1, 32, 1)  # (B, C, 96)\n",
    "\n",
    "        adj = self.graph_learner(x)           # (B, C, C)\n",
    "\n",
    "        x = self.transformer(x, adj)          # (B, C, 96)\n",
    "\n",
    "        x = x.mean(dim=1)                     # global pooling\n",
    "\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f835df7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 29280 samples\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"DEAP_dataset\"\n",
    "\n",
    "full_dataset = DEAPDataset(\n",
    "    data_dir=data_dir,\n",
    "    label_type=\"valence\",  # or \"arousal\"\n",
    "    window_size=256,\n",
    "    step_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70a28233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 01: train=26840, test=2440\n",
      "Subject 01 accuracy: 48.81%\n",
      "Subject 02: train=26840, test=2440\n",
      "Subject 02 accuracy: 62.50%\n",
      "Subject 03: train=26840, test=2440\n",
      "Subject 03 accuracy: 54.84%\n",
      "Skipping subject 04 (empty split)\n",
      "Subject 05: train=26840, test=2440\n",
      "Subject 05 accuracy: 59.30%\n",
      "Skipping subject 06 (empty split)\n",
      "Subject 07: train=26840, test=2440\n",
      "Subject 07 accuracy: 53.89%\n",
      "Subject 08: train=26840, test=2440\n",
      "Subject 08 accuracy: 54.30%\n",
      "Subject 09: train=26840, test=2440\n",
      "Subject 09 accuracy: 55.70%\n",
      "Skipping subject 10 (empty split)\n",
      "Subject 11: train=26840, test=2440\n",
      "Subject 11 accuracy: 59.39%\n",
      "Skipping subject 12 (empty split)\n",
      "Skipping subject 13 (empty split)\n",
      "Skipping subject 14 (empty split)\n",
      "Subject 15: train=26840, test=2440\n",
      "Subject 15 accuracy: 49.84%\n",
      "Subject 16: train=26840, test=2440\n",
      "Subject 16 accuracy: 33.32%\n",
      "Skipping subject 17 (empty split)\n",
      "Skipping subject 18 (empty split)\n",
      "Skipping subject 19 (empty split)\n",
      "Skipping subject 20 (empty split)\n",
      "Skipping subject 21 (empty split)\n",
      "Subject 22: train=26840, test=2440\n",
      "Subject 22 accuracy: 47.58%\n",
      "Skipping subject 23 (empty split)\n",
      "Skipping subject 24 (empty split)\n",
      "Subject 25: train=26840, test=2440\n",
      "Subject 25 accuracy: 51.43%\n",
      "Skipping subject 26 (empty split)\n",
      "Skipping subject 27 (empty split)\n",
      "Skipping subject 28 (empty split)\n",
      "Skipping subject 29 (empty split)\n",
      "Skipping subject 30 (empty split)\n",
      "Skipping subject 31 (empty split)\n",
      "Skipping subject 32 (empty split)\n"
     ]
    }
   ],
   "source": [
    "subject_accuracies = []\n",
    "\n",
    "for subject in range(1, 33):\n",
    "\n",
    "    train_set, test_set = loso_split(full_dataset, subject)\n",
    "    if len(test_set) == 0 or len(train_set) == 0:\n",
    "        print(f\"Skipping subject {subject:02d} (empty split)\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Subject {subject:02d}: \"\n",
    "        f\"train={len(train_set)}, test={len(test_set)}\")\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_set, batch_size=32, shuffle=True,\n",
    "        num_workers=4, pin_memory=True\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_set, batch_size=32, shuffle=False,\n",
    "        num_workers=4, pin_memory=True\n",
    "    )\n",
    "\n",
    "    model = DySTGATFormer().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # ---- TRAIN ----\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        for x, y, _ in train_loader:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(x), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # ---- EVALUATE ----\n",
    "    acc = evaluate(model, test_loader, device)\n",
    "    subject_accuracies.append(acc)\n",
    "\n",
    "    print(f\"Subject {subject:02d} accuracy: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b0d7c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOSO Accuracy: 52.58 ± 7.24\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "mean_acc = np.mean(subject_accuracies)\n",
    "std_acc = np.std(subject_accuracies)\n",
    "\n",
    "print(f\"\\nLOSO Accuracy: {mean_acc:.2f} ± {std_acc:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
